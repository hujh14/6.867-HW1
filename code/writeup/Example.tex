\documentclass[a4paper,twoside]{article}

\usepackage{epsfig}
\usepackage{subfigure}
\usepackage{calc}
\usepackage{amssymb}
\usepackage{amstext}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{multicol}
\usepackage{pslatex}
\usepackage{apalike}
\usepackage{SCITEPRESS}
\usepackage[small]{caption}

\subfigtopskip=0pt
\subfigcapskip=0pt
\subfigbottomskip=0pt

\begin{document}

\title{6.867 Machine Learning  \subtitle{Homework 1} }

\maketitle

% **************************************************************************************************
 % Problem 1
% **************************************************************************************************

\section{\uppercase{Implementing Gradient Descent}}

\noindent Gradient descent is an iterative procedure for find a vector that minimize an objective function. Typically, the vector is our parameters and the objective function is the cost function. In each iteration, we find the gradient of the objective function evaluated at the vector and update the vector in the direction of the negative gradient.

\subsection{Basic Gradient Descent}

\noindent To demonstrate the gradient descent algorithm, we began by finding the minimum of two well defined functions with closed form derivatives shown below.

\medskip
\noindent Negative Gaussian:
\begin{equation}
f(x) = - \frac{1}{\sqrt{(2\pi)^n |\Sigma|}} exp[-\frac{1}{2} (x-u)^T\Sigma^{-1}(x-u)]
\end{equation}
\begin{equation}
\frac{\partial f(x)}{\partial x} = -f(x) \Sigma^{-1} (x-u)
\end{equation}

\noindent Quadratic Bowl:
\begin{equation}
f(x) = \frac{1}{2} x^T A x - x^T b
\end{equation}
\begin{equation}
\frac{\partial f(x)}{\partial x} = Ax - b
\end{equation}

How did we do?

The gradient descent algorithm takes three additional parameters, the starting guess, step size, and convergence criterion. Each affects the end result of the algorithm. The starting guess is important because gradient descent iteratively follows the gradient. Thus it can get stuck in local minimum. By running the algorithm repeated with random initialization, we increase our chance of finding a global minimum. The step size affects convergence behavior of the algorithm. As depicted in figure 1, if the step size is too small, the algorithm will converge slowly. If the step size is too big, the algorithm will overshoot the minimum and oscillate, converging more slowly. If the step size is much too big, the algorithm will actually diverge. This is depicted in figure 1 where for different step sizes, the norm of the gradients are plotted over time. The convergence criterion determines for how little change in cost function is it okay to stop. Decreasing this gives greater accuracy but increase runtime.

Include Graphs at the end!!

\subsection{Central Difference Approximation}

For many objective functions, it is impossible to write a closed form gradient function. Thus, use central difference approxiation to approximate the gradient. For each dimension $i$, estimate its partial derivative by 
\begin{equation}
\bigtriangledown_i f(x) = \frac{f(x+d*\hat{\i}) - f(x-d*\hat{\i})}{2d}
\end{equation}
for some small $d$. The larger $d$ is, the more inaccurate the gradient approximation is. We will use $d = 10^{-3}$.

\subsection{Batch vs. Stochastic Gradient Descent}
Now use gradient descent to find parameters $\theta$ that minimizes the least squared error objective function
\begin{equation}
J(\theta) = ||X\theta - y||^2
\end{equation}
where each row of $X$ and $y$ is a data sample pair. 

In batch gradient descent, $\theta$ is updated with the gradient of the cost function for the entire training dataset.
Use the gradient function
\begin{equation}
\bigtriangledown_\theta J(theta) = 2 (X\theta - y) * X
\end{equation}
That equation is probs wrong.
How quickly did we converge and what did we converge to? 

In contrast, stochastic gradient descent updates $\theta$ with the gradient of the cost function for each data point. $\theta$ is updated according to 
\begin{equation}
\theta_{t+1} = \theta_t - \eta_t \bigtriangledown_\theta J(\theta_t; x^{(i)}, y^{(i)})
\end{equation}
where $\eta$ is the learning rate and
\begin{equation}
J(\theta_t; x^{(i)}, y^{(i)}) = (x^{(i)T} \theta_t - y^{(i)})^2
\end{equation}
\begin{equation}
\bigtriangledown_\theta J(\theta_t; x^{(i)}, y^{(i)}) = 2(x^{(i)T} \theta_t - y^{(i)}) x^{(i)}.
\end{equation}

 We iterate through the entire dataset for $n$ rounds and for each round, we iterate through the data points in a different order. We converge when the cost between rounds decreases by less than a certain threshold. 


 Compare the behavior of the two algorithms!!!


% **************************************************************************************************
 % Problem 2
% **************************************************************************************************

\section{\uppercase{Linear Basis Function Regression}}

You can write stuff here to but don't have to.

\subsection{Closed Form Solution}

\subsection{Gradient Descent Objective Functions}

Write functions to compute SSE and derivative.

\subsection{Batch vs Stochastic Gradient Descent}

Compare!

\subsection{Cosine Basis Functions}

Shtuff.

% **************************************************************************************************
 % Problem 3
% **************************************************************************************************

\section{\uppercase{Ridge Regression}}

\subsection{Closed Form Solution}

\subsection{Results?}

% **************************************************************************************************
 % Problem 4
% **************************************************************************************************

\section{\uppercase{Sparsity and LASSO}}

\subsection{Lasso}



\vfill
\end{document}

